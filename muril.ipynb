{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXlltksKEtU5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP9RwF4DZlch"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFUxs2UQZ18Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from transformers import TFAutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ReNgdWcaFZi"
      },
      "outputs": [],
      "source": [
        "# Load the Kannada dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/processed_sentiment_140_en_mr.csv', encoding='utf-8', names=['polarity','id','text','lang'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P231oqGyaXya"
      },
      "outputs": [],
      "source": [
        "# Extract the necessary columns\n",
        "data_x = data['text'].tolist()\n",
        "data_y = data['polarity'].tolist()\n",
        "data_lang = data['lang'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zikkh86XajWg"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYG5Ln94avXm"
      },
      "outputs": [],
      "source": [
        "# Processing label of training/testing data\n",
        "label_data = data['polarity'].values\n",
        "senti = [0, 4]\n",
        "mapping = {senti[x]: x for x in range(len(senti))}\n",
        "\n",
        "# Integer representation\n",
        "for x in range(len(label_data)):\n",
        "    label_data[x] = mapping[label_data[x]]\n",
        "\n",
        "# Converting to one-hot encoding\n",
        "y_data = to_categorical(label_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g3h7ikvbyFa",
        "outputId": "b254de0b-2652-4f11-c277-067545bebf1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "y_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc-7NuM9c-2e"
      },
      "outputs": [],
      "source": [
        "# Filter the data for Kannada language\n",
        "language_indices = [i for i, text in enumerate(data_x) if bool(re.search(r'[अ-औक-ह]', str(text)))]\n",
        "data_x_language= [data_x[i] for i in language_indices]\n",
        "data_y_language= [data_y[i] for i in language_indices]\n",
        "\n",
        "# Processing label of training/testing data\n",
        "label_data = np.array(data_y_language)\n",
        "senti = [0, 4]\n",
        "mapping = {senti[x]: x for x in range(len(senti))}\n",
        "label_data = np.array([mapping[label] for label in label_data])\n",
        "\n",
        "# Converting to one-hot encoding\n",
        "y_data = to_categorical(label_data)\n",
        "\n",
        "# Perform train-test split\n",
        "raw_docs_train, raw_docs_test, y_train, y_test = train_test_split(data_x_language, y_data, test_size=0.2, random_state=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R-je64udNHR"
      },
      "outputs": [],
      "source": [
        "MAX_NB_WORDS = 100000\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
        "\n",
        "print(\"Pre-processing train data...\")\n",
        "processed_docs_train = []\n",
        "for line in raw_docs_train:\n",
        "    tokens = tokenizer.tokenize(line)\n",
        "    processed_docs_train.append(\" \".join(tokens))\n",
        "\n",
        "print(\"Pre-processing test data...\")\n",
        "processed_docs_test = []\n",
        "for line in raw_docs_test:\n",
        "    tokens = tokenizer.tokenize(line)\n",
        "    processed_docs_test.append(\" \".join(tokens))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQxCzWJDdVob"
      },
      "outputs": [],
      "source": [
        "# Tokenize input data\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(processed_docs_train + processed_docs_test)\n",
        "word_seq_train = tokenizer.texts_to_sequences(processed_docs_train)\n",
        "word_seq_test = tokenizer.texts_to_sequences(processed_docs_test)\n",
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIbOiUGAdZor"
      },
      "outputs": [],
      "source": [
        "# Pad sequences\n",
        "max_seq_len = max(len(word_seq_train[0]), len(word_seq_test[0]))\n",
        "word_seq_train = pad_sequences(word_seq_train, maxlen=max_seq_len)\n",
        "word_seq_test = pad_sequences(word_seq_test, maxlen=max_seq_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDDkeRF4ddGe"
      },
      "outputs": [],
      "source": [
        "# Load the transformer model and tokenizer\n",
        "model_name = \"google/muril-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = TFAutoModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AotyRS-idg6o"
      },
      "outputs": [],
      "source": [
        "# Embedding matrix\n",
        "embed_dim = model.config.hidden_size\n",
        "print('Preparing embedding matrix...')\n",
        "words_not_found = []\n",
        "nb_words = min(MAX_NB_WORDS, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= nb_words:\n",
        "        continue\n",
        "    encoded_input = tokenizer.encode(word, add_special_tokens=False)\n",
        "    if len(encoded_input) > 0:\n",
        "        embedding_vector = model(np.array([encoded_input]))[0][0].numpy()\n",
        "        if len(embedding_vector.shape) != 1:\n",
        "            embedding_vector = np.mean(embedding_vector, axis=0)  # Average pooling over multiple tokens\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        words_not_found.append(word)\n",
        "\n",
        "print('Number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rq3vJwMdnNk"
      },
      "outputs": [],
      "source": [
        "# Model architecture\n",
        "num_filters = 12\n",
        "weight_decay = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flclXxP9yvRt"
      },
      "source": [
        "==================================================LSTM============================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SchFvDJPZJpi"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "LV_Ghy317d0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXZ0zOrtY9ad"
      },
      "outputs": [],
      "source": [
        "#LSTM\n",
        "lstm_out = 128\n",
        "num_classes = 2\n",
        "model_LSTM = Sequential()\n",
        "model_LSTM.add(Embedding(nb_words, embed_dim,\n",
        "          weights=[embedding_matrix], input_length=max_seq_len, trainable=False))\n",
        "model_LSTM.add(Bidirectional(LSTM(lstm_out, dropout=0.2)))\n",
        "model_LSTM.add(Dense(128, activation = 'relu'))\n",
        "model_LSTM.add(Dropout(0.5))\n",
        "model_LSTM.add(Dense(64, activation = 'relu'))\n",
        "model_LSTM.add(Dense(num_classes, activation='softmax'))  #multi-label (k-hot encoding)\n",
        "adam = tf.optimizers.Adam()\n",
        "model_LSTM.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "model_LSTM.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSjm45z_Y9af"
      },
      "outputs": [],
      "source": [
        "#training params\n",
        "batch_size_LSTM = 256\n",
        "num_epochs_LSTM = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-tkl0lDY9af"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"training/LSTM/language_detection/trained_cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXlp-BcMY9ag"
      },
      "outputs": [],
      "source": [
        "#model training_LSTM\n",
        "hist_LSTM = model_LSTM.fit(word_seq_train, y_train, batch_size=batch_size_LSTM, epochs=num_epochs_LSTM,validation_split=0.1, shuffle=True, verbose=1,callbacks=[cp_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model_LSTM.predict(word_seq_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Convert one-hot encoded y_test to categorical labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test_labels, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test_labels, y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_labels, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test_labels, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "-XIxnR2l78iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6KYcO2oy6gL"
      },
      "source": [
        "muril-lstm-LANGUAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfCUzaNozFz5"
      },
      "source": [
        "=========================================CNN==================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNeeVp4ldwSa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Training CNN...\")\n",
        "model = Sequential()\n",
        "model.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_seq_len, trainable=False))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(2))\n",
        "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(weight_decay)))\n",
        "model.add(Dense(2, activation='softmax'))  # Assuming binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT0BI9vjdz6B"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Training parameters\n",
        "batch_size = 256\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "history = model.fit(word_seq_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.1, shuffle=True)\n"
      ],
      "metadata": {
        "id": "YbLqvSXNzWiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(word_seq_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Convert one-hot encoded y_test to categorical labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test_labels, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test_labels, y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_labels, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test_labels, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "_zdKrIUvzhMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MURIL-CNN-LANGUAGE"
      ],
      "metadata": {
        "id": "K3ODP8la0B1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=================================================================================GRU-================="
      ],
      "metadata": {
        "id": "U4t8DBehzmIU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY3IAQIfI5Rv"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Embedding,  GRU, SpatialDropout1D, Bidirectional, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vABe7GV_Inac"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout\n",
        "gru_out = 128\n",
        "num_classes = 2\n",
        "model_GRU = keras.Sequential()\n",
        "model_GRU.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_seq_len, trainable=False))\n",
        "model_GRU.add(Bidirectional(GRU(gru_out, dropout=0.2)))\n",
        "model_GRU.add(Dense(128, activation='relu'))\n",
        "model_GRU.add(Dropout(0.5))\n",
        "model_GRU.add(Dense(64, activation='relu'))\n",
        "model_GRU.add(Dense(num_classes, activation='softmax'))  # multi-label (k-hot encoding)\n",
        "adam = tf.optimizers.Adam()\n",
        "model_GRU.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "model_GRU.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6dWsGkMRTeg"
      },
      "outputs": [],
      "source": [
        "#training params\n",
        "batch_size = 256\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MnRG9XlRX21"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/Twitter_dataset/trainined_gru_cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                  save_weights_only=True,\n",
        "                                                 verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsWfe7KERdhN"
      },
      "outputs": [],
      "source": [
        "#model training\n",
        "hist = model_GRU.fit(word_seq_train, y_train, batch_size=batch_size, epochs=num_epochs,validation_split=0.1, shuffle=True, verbose=1,callbacks=[cp_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model_GRU.predict(word_seq_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Convert one-hot encoded y_test to categorical labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test_labels, y_pred)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test_labels, y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_labels, y_pred)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_test_labels, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "S2crVJib7Uk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUN05BpODcR5"
      },
      "source": [
        "muril-gru-LANGUAGE"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}